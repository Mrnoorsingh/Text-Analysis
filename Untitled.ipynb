{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib import parse,request\n",
    "import requests\n",
    "from nltk.tokenize import word_tokenize \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "from string import digits\n",
    "from nltk.corpus import stopwords,cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of stopwords(Generic)\n",
    "stopword_gen=pd.read_csv(\"StopWords_Generic.txt\")\n",
    "stopword_gen=list(stopword_gen.ABOUT)\n",
    "#create positive negative dictionary from master dictionary\n",
    "df=pd.read_csv(\"LoughranMcDonald_MasterDictionary_2018.csv\")\n",
    "df=df.loc[:,[\"Word\",\"Negative\",\"Positive\"]]\n",
    "df=df[(df.Negative!=0) | (df.Positive!=0)]\n",
    "df=df[~df.Word.isin(stopword)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_url=\"https://www.sec.gov/Archives/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-000413.txt'"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exl=pd.read_excel(\"cik_list.xlsx\",sheet_name=0)\n",
    "rel_url=\"edgar/data/3662/0000950170-98-000413.txt\"\n",
    "url=parse.urljoin(abs_url,rel_url)\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=requests.get(url)\n",
    "soup=BeautifulSoup(txt.content,\"lxml\")\n",
    "for tag in soup([\"table\",\"sec-header\"]):\n",
    "    tag.decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove digits with decimal points\n",
    "text=re.sub(r\"[0-9]+\\.+[0-9]+\",\"\",text)\n",
    "#remove digits\n",
    "remove_digits=str.maketrans(\"\", \"\",digits)\n",
    "text=text.translate(remove_digits)\n",
    "#remove punctuations except periods and apostrophe\n",
    "text=re.sub(r'[^\\w\\.\\'\\s]',\"\",text)\n",
    "#remove stopwords(NLTK) and extra spaces\n",
    "stopword=set(stopwords.words(\"english\"))\n",
    "text=\" \".join([word for word in text.split() if word not in stopword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern=\"MANAGEMENT'S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATION (.+?)ITEM \\.\"\n",
    "pattern1=r\"ITEM [0-9]\\. QUANTITATIVE AND QUALITATIVE DISCLOSURES (.+?)ITEM [0-9]\\.\"\n",
    "substring=re.search(pattern,text,re.DOTALL)\n",
    "string=substring.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2125\n"
     ]
    }
   ],
   "source": [
    "#count words in the text\n",
    "split_words=string.split()\n",
    "#remove periods from list\n",
    "clean_list=list(map(lambda x:re.sub(r\"[^a-zA-Z\\']\",\"\",x),split_words))\n",
    "clean_list=list(filter(None,clean_list))\n",
    "print(len(clean_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count positive and negative words in the text\n",
    "positive=0\n",
    "negative=0\n",
    "for word in clean_list:\n",
    "    if word.upper() in list(df.Word):\n",
    "        if df.loc[df[\"Word\"]==word.upper(),\"Positive\"].iloc[0] != 0:\n",
    "            positive+=1\n",
    "        else:\n",
    "            negative+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.56\n"
     ]
    }
   ],
   "source": [
    "#polarity score\n",
    "polarity_score=(positive - negative)/((positive + negative) + 0.000001)\n",
    "print(round(polarity_score,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04282352939161246"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subjectivity score\n",
    "sub_score=(positive+negative)/((len(clean_list))+0.000001)\n",
    "sub_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment category\n",
    "def category(polarity):\n",
    "    if polarity <= -0.5:\n",
    "        cat=\"Most Negative\"\n",
    "    elif -0.5 < polarity < 0:\n",
    "        cat=\"Negative\"\n",
    "    elif polarity == 0:\n",
    "        cat=\"Neutral\"\n",
    "    elif 0 < polarity < 0.5:\n",
    "        cat=\"Positive\"\n",
    "    else:\n",
    "        cat=\"Very Positive\"\n",
    "    \n",
    "    return cat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count syllables\n",
    "def syllable_count(word):\n",
    "    try:\n",
    "        count=max([len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]])\n",
    "        return count\n",
    "    except KeyError:\n",
    "        word=word.lower()\n",
    "        count=0\n",
    "        vowels=\"aeiouy\"\n",
    "        #count if first letter is vowel\n",
    "        if word[0] in vowels:\n",
    "            count+=1   \n",
    "        for index in range(1, len(word)):\n",
    "            #count the vowel in only if previous letter is not vowel\n",
    "            if index==(len(word) - 2) and (word[index]+word[index+1]==\"ed\" or word[index]+word[index+1]==\"es\"): \n",
    "                break    \n",
    "            if word[index] in vowels and word[index - 1] not in vowels:\n",
    "                count+=1    \n",
    "        if word.endswith(\"e\"):\n",
    "            count-=1\n",
    "        if count==0:\n",
    "            count+=1\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis of readability\n",
    "avg_sent_length=len(clean_list)/len(string.split(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.42\n"
     ]
    }
   ],
   "source": [
    "#syllable count per word\n",
    "average=sum(list(map(lambda x:syllable_count(x),clean_list)))/len(clean_list)\n",
    "print(round(average,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "887"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count complex words\n",
    "complex_words=list(map(lambda x:syllable_count(x),clean_list))\n",
    "complex_words=sum(i>2 for i in complex_words)\n",
    "complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count personal pronouns\n",
    "pers_pronoun=[\"i\",\"we\",\"ours\",\"us\"]\n",
    "t=\"i am we\"\n",
    "pattern=\"|\".join(r\"\\b%s\\b\" % w for w in pers_pronoun)\n",
    "match=re.compile(pattern)\n",
    "pro_count=len(match.findall(string))#ignorecase or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passive auxillary verbs\n",
    "aux_verb=[\"to be\", \"to have\", \"will be\", \"has been\", \"have been\", \"had been\", \"will have been\",\n",
    "               \"being\", \"am\", \"are\", \"is\", \"was\", \"were\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of irregular verbs(past participle)\n",
    "verb_url=\"https://www.worldclasslearning.com/english/irregular-verb-forms.html\"\n",
    "html=requests.get(verb_url)\n",
    "soup=BeautifulSoup(html.content,\"lxml\")\n",
    "verb_text=soup.prettify()\n",
    "\n",
    "tr=soup(\"tr\")[1:]\n",
    "irr_verb=[tag.find_all(\"td\")[3].get_text() for tag in tr]#remove double words pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passive verbs\n",
    "verb_pattern=\"|\".join(r\"\\b%s\\b\" % w for w in aux_verb)\n",
    "verb_match=re.compile(verb_pattern,flags=(re.IGNORECASE))\n",
    "find_verb=verb_match.findall(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passive words\n",
    "#find passive auxillary verbs\n",
    "verb_pattern=\"|\".join(r\"\\b%s\\b\" % w for w in aux_verb)\n",
    "verb_match=re.compile(verb_pattern,flags=(re.IGNORECASE))\n",
    "find_verb=verb_match.findall(cc)\n",
    "\n",
    "#find passive words\n",
    "passive_words=0\n",
    "for verb in find_verb:\n",
    "    irreg_verb=re.compile(r\"\\b\"+verb+\" (\\w+)\")\n",
    "    next_word=irreg_verb.findall(cc)\n",
    "    for word in next_word:\n",
    "        if word in irr_verb or word.endswith(\"ed\"):\n",
    "            passive_words+=1\n",
    "passive_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.369411764705882"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average word length\n",
    "avg_word_length=sum(list(map(lambda x:len(x),clean_list)))/len(clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.62"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#analysis of readability\n",
    "#average sentence length\n",
    "string1=string.replace(\"U.S.\",\"\")\n",
    "num_sent=string1.split(\".\")\n",
    "avg_sent_length=len(clean_list)/len(num_sent)\n",
    "avg_sent_length=round(avg_sent_length,2)\n",
    "\n",
    "#fraction of complex words\n",
    "frac=complex_words/len(clean_list)\n",
    "\n",
    "#fog index\n",
    "fog=0.4*(avg_sent_length+frac)\n",
    "fog=round(fog,2)\n",
    "fog"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
