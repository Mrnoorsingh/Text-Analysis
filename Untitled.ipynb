{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib import parse,request\n",
    "import requests\n",
    "from nltk.tokenize import word_tokenize \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "from string import digits\n",
    "from nltk.corpus import stopwords,cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of stopwords(Generic)\n",
    "stopword_gen=pd.read_csv(\"StopWords_Generic.txt\")\n",
    "stopword_gen=list(stopword_gen.ABOUT)\n",
    "#create positive negative dictionary from master dictionary\n",
    "df=pd.read_csv(\"LoughranMcDonald_MasterDictionary_2018.csv\")\n",
    "df=df.loc[:,[\"Word\",\"Negative\",\"Positive\"]]\n",
    "df=df[(df.Negative!=0) | (df.Positive!=0)]\n",
    "df=df[~df.Word.isin(stopword)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_url=\"https://www.sec.gov/Archives/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-000413.txt'"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exl=pd.read_excel(\"cik_list.xlsx\",sheet_name=0)\n",
    "rel_url=\"edgar/data/3662/0000950170-98-000413.txt\"\n",
    "url=parse.urljoin(abs_url,rel_url)\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=requests.get(url)\n",
    "soup=BeautifulSoup(txt.content,\"lxml\")\n",
    "for tag in soup([\"table\",\"sec-header\"]):\n",
    "    tag.decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove digits with decimal points\n",
    "text=re.sub(r\"[0-9]+\\.+[0-9]+\",\"\",text)\n",
    "#remove digits\n",
    "remove_digits=str.maketrans(\"\", \"\",digits)\n",
    "text=text.translate(remove_digits)\n",
    "#remove punctuations except periods and apostrophe\n",
    "text=re.sub(r'[^\\w\\.\\'\\s]',\"\",text)\n",
    "#remove stopwords(NLTK) and extra spaces\n",
    "stopword=set(stopwords.words(\"english\"))\n",
    "text=\" \".join([word for word in text.split() if word not in stopword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern=\"MANAGEMENT'S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATION (.+?)ITEM \\.\"\n",
    "pattern1=r\"ITEM [0-9]\\. QUANTITATIVE AND QUALITATIVE DISCLOSURES (.+?)ITEM [0-9]\\.\"\n",
    "substring=re.search(pattern,text,re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2125\n"
     ]
    }
   ],
   "source": [
    "#count words in the text\n",
    "split_words=substring.group(1).split()\n",
    "#remove periods from list\n",
    "clean_list=list(map(lambda x:re.sub(r\"[^a-zA-Z\\']\",\"\",x),split_words))\n",
    "clean_list=list(filter(None,clean_list))\n",
    "print(len(clean_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count positive and negative words in the text\n",
    "positive=0\n",
    "negative=0\n",
    "for word in clean_list:\n",
    "    if word.upper() in list(df.Word):\n",
    "        if df.loc[df[\"Word\"]==word.upper(),\"Positive\"].iloc[0] != 0:\n",
    "            positive+=1\n",
    "        else:\n",
    "            negative+=1    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.560439554280884"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#polarity score\n",
    "polarity_score=(positive - negative)/((positive + negative) + 0.000001)\n",
    "polarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count syllables\n",
    "def syllable_count(word):\n",
    "    try:\n",
    "        count=max([len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]])\n",
    "        return count\n",
    "    except KeyError:\n",
    "        word=word.lower()\n",
    "        count=0\n",
    "        vowels=\"aeiouy\"\n",
    "        #count if first letter is vowel\n",
    "        if word[0] in vowels:\n",
    "            count+=1   \n",
    "        for index in range(1, len(word)):\n",
    "            #count the vowel in only if previous letter is not vowel\n",
    "            if index==(len(word) - 2) and (word[index]+word[index+1]==\"ed\" or word[index]+word[index+1]==\"es\"): \n",
    "                break    \n",
    "            if word[index] in vowels and word[index - 1] not in vowels:\n",
    "                count+=1    \n",
    "        if word.endswith(\"e\"):\n",
    "            count-=1\n",
    "        if count==0:\n",
    "            count+=1\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.42\n"
     ]
    }
   ],
   "source": [
    "#syllable count per word\n",
    "average=sum(list(map(lambda x:syllable_count(x),clean_list)))/len(clean_list)\n",
    "print(round(average,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "887"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count complex words\n",
    "complex_words=list(map(lambda x:syllable_count(x),clean_list))\n",
    "complex_words=sum(i>2 for i in complex_words)\n",
    "complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count personal pronouns\n",
    "pers_pronoun=[\"i\",\"we\",\"ours\",\"us\"]\n",
    "string=substring.group(1)\n",
    "t=\"i am we\"\n",
    "pattern=\"|\".join(r\"\\b%s\\b\" % w for w in pers_pronoun)\n",
    "match=re.compile(pattern)\n",
    "pro_count=len(match.findall(string))#ignorecase or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passive verbs\n",
    "passive_auxillary_verb=[\"to be\", \"to have\", \"will be\", \"has been\", \"have been\", \"had been\", \"will have been\",\n",
    "               \"being\", \"am\", \"are\", \"is\", \"was\", \"were\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_url=\"https://www.worldclasslearning.com/english/irregular-verb-forms.html\"\n",
    "html=requests.get(verb_url)\n",
    "soup=BeautifulSoup(html.content,\"lxml\")\n",
    "verb_text=soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abode',\n",
       " 'alit',\n",
       " 'arisen',\n",
       " 'awoken',\n",
       " 'been',\n",
       " 'born/borne',\n",
       " 'beaten',\n",
       " 'become',\n",
       " 'befallen',\n",
       " 'begun',\n",
       " 'beheld',\n",
       " 'bent',\n",
       " 'bereft',\n",
       " 'besought',\n",
       " 'bet',\n",
       " 'bidden',\n",
       " 'bid',\n",
       " 'bound',\n",
       " 'bitten',\n",
       " 'bled',\n",
       " 'blown',\n",
       " 'broken',\n",
       " 'bred',\n",
       " 'brought',\n",
       " 'broadcast',\n",
       " 'built',\n",
       " 'burnt',\n",
       " 'burst',\n",
       " 'bust',\n",
       " 'bought',\n",
       " 'cast',\n",
       " 'caught',\n",
       " 'chidden',\n",
       " 'chosen',\n",
       " 'cloven/cleft',\n",
       " 'clung',\n",
       " 'clad',\n",
       " 'come',\n",
       " 'cost',\n",
       " 'crept',\n",
       " 'cut',\n",
       " 'dealt',\n",
       " 'dug',\n",
       " 'done',\n",
       " 'drawn',\n",
       " 'dreamt',\n",
       " 'drunk',\n",
       " 'driven',\n",
       " 'dwelt',\n",
       " 'eaten',\n",
       " 'fallen',\n",
       " 'fart',\n",
       " 'fed',\n",
       " 'felt',\n",
       " 'fought',\n",
       " 'found',\n",
       " 'fit',\n",
       " 'fled',\n",
       " 'flung',\n",
       " 'flown',\n",
       " 'forbidden',\n",
       " 'forecast',\n",
       " 'forgotten',\n",
       " 'forgiven',\n",
       " 'forsaken',\n",
       " 'frozen',\n",
       " 'gainsaid',\n",
       " 'got',\n",
       " 'girt',\n",
       " 'given',\n",
       " 'gone',\n",
       " 'graven',\n",
       " 'grown',\n",
       " 'hung',\n",
       " 'had',\n",
       " 'heard',\n",
       " 'hove',\n",
       " 'hewn',\n",
       " 'hidden',\n",
       " 'hit',\n",
       " 'held',\n",
       " 'hurt',\n",
       " 'inlaid',\n",
       " 'input',\n",
       " 'kept',\n",
       " 'knelt',\n",
       " 'knit',\n",
       " 'known',\n",
       " 'laden',\n",
       " 'laid',\n",
       " 'led',\n",
       " 'leant',\n",
       " 'leapt',\n",
       " 'learnt',\n",
       " 'left',\n",
       " 'lent',\n",
       " 'let',\n",
       " 'lain',\n",
       " 'lit',\n",
       " 'lost',\n",
       " 'made',\n",
       " 'meant',\n",
       " 'met',\n",
       " 'mistaken',\n",
       " 'mown',\n",
       " 'partaken',\n",
       " 'paid',\n",
       " 'pled',\n",
       " 'put',\n",
       " 'quit',\n",
       " 'read (રેડ)',\n",
       " 'rent',\n",
       " 'rid',\n",
       " 'ridden',\n",
       " 'rung',\n",
       " 'risen',\n",
       " 'run',\n",
       " 'sawn',\n",
       " 'said',\n",
       " 'seen',\n",
       " 'sought',\n",
       " 'sold',\n",
       " 'sent',\n",
       " 'set',\n",
       " 'sewn',\n",
       " 'shaken',\n",
       " 'shaven',\n",
       " 'shorn',\n",
       " 'shed',\n",
       " 'shone',\n",
       " 'shit',\n",
       " 'shod',\n",
       " 'shot',\n",
       " 'shown',\n",
       " 'shrunk',\n",
       " 'shriven',\n",
       " 'shut',\n",
       " 'sung',\n",
       " 'sunk',\n",
       " 'sat',\n",
       " 'slain',\n",
       " 'slept',\n",
       " 'slid',\n",
       " 'slung',\n",
       " 'slunk',\n",
       " 'slit',\n",
       " 'smelt',\n",
       " 'smitten',\n",
       " 'spoken',\n",
       " 'sped',\n",
       " 'spelt',\n",
       " 'spent',\n",
       " 'spilt',\n",
       " 'spun',\n",
       " 'spat',\n",
       " 'split',\n",
       " 'spoilt',\n",
       " 'spread',\n",
       " 'sprung',\n",
       " 'stood',\n",
       " 'stolen',\n",
       " 'stuck',\n",
       " 'stung',\n",
       " 'stunk',\n",
       " 'strewn',\n",
       " 'stridden',\n",
       " 'stricken',\n",
       " 'strung',\n",
       " 'striven',\n",
       " 'sworn',\n",
       " 'sweat',\n",
       " 'swept',\n",
       " 'swollen',\n",
       " 'swum',\n",
       " 'swung',\n",
       " 'taken',\n",
       " 'taught',\n",
       " 'torn',\n",
       " 'told',\n",
       " 'thought',\n",
       " 'thriven',\n",
       " 'thrown',\n",
       " 'thrust',\n",
       " 'trodden',\n",
       " 'understood',\n",
       " 'woken',\n",
       " 'way-laid',\n",
       " 'worn',\n",
       " 'woven',\n",
       " 'wed',\n",
       " 'wept',\n",
       " 'welcomed',\n",
       " 'went',\n",
       " 'wet',\n",
       " 'won',\n",
       " 'wound',\n",
       " 'withdrawn',\n",
       " 'wrung',\n",
       " 'written']"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create list of irregular verbs(past participle)\n",
    "tr=soup(\"tr\")[1:]\n",
    "irr_verb=[tag.find_all(\"td\")[3].get_text() for tag in tr]\n",
    "irr_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cloven', 'cleft']"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c='cloven/cleft'\n",
    "c.split(\"/\")`dd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
